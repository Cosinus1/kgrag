# app/streamlit_app_fixed.py
# Version am√©lior√©e avec meilleure gestion des entit√©s et debugging

import streamlit as st
import sys
sys.path.append('.')

from dotenv import load_dotenv
import os
from pathlib import Path
import re

# Load environment first
load_dotenv()

# Import after loading env
from src.graph.graph_queries import GraphQueries
from src.embeddings.vector_store import VectorStore
from src.rag.graph_traverser import GraphTraverser
from src.rag.context_builder import ContextBuilder
from src.rag.llm_interface import LLMInterface
from src.extraction.entity_extractor import EntityExtractor

# Configuration de la page
st.set_page_config(
    page_title="Knowledge Graph RAG",
    page_icon="üß†",
    layout="wide"
)

# Initialisation de la session
@st.cache_resource
def init_components():
    """Initialize all components once."""
    try:
        # Check if ChromaDB directory exists
        chroma_paths = [Path("chroma_db"), Path("./chroma_db"), Path("../chroma_db")]
        chroma_found = any(p.exists() for p in chroma_paths)
        
        if not chroma_found:
            st.error("‚ùå Vector store (ChromaDB) not found!")
            st.info("Ex√©cutez: python scripts/04_generate_embeddings.py")
            st.stop()
        
        components = {
            'graph_queries': GraphQueries(
                uri=os.getenv("NEO4J_URI"),
                user=os.getenv("NEO4J_USER"),
                password=os.getenv("NEO4J_PASSWORD")
            ),
            'vector_store': VectorStore(),
            'llm': LLMInterface(),
            'entity_extractor': EntityExtractor()
        }
        
        # Verify vector store has data
        try:
            count = components['vector_store'].count()
            if count == 0:
                st.warning(f"‚ö†Ô∏è Vector store existe mais est vide (0 entit√©s)")
                st.info("Ex√©cutez: python scripts/04_generate_embeddings.py")
            else:
                st.success(f"‚úì Vector store charg√©: {count:,} entit√©s")
        except:
            pass
        
        return components
        
    except Exception as e:
        st.error(f"‚ùå Error initializing components: {e}")
        st.info("Assurez-vous que:")
        st.info("- Neo4j est d√©marr√©")
        st.info("- Les donn√©es sont g√©n√©r√©es (scripts 01-04)")
        st.info("- La cl√© API LLM est configur√©e dans .env")
        return None

def extract_keywords_from_question(question: str) -> list:
    """Extrait des mots-cl√©s d'une question si aucune entit√© n'est d√©tect√©e."""
    # Mots √† ignorer
    stop_words = {
        'qui', 'est', 'quoi', 'o√π', 'quand', 'comment', 'pourquoi',
        'le', 'la', 'les', 'un', 'une', 'des', 'de', 'du',
        'parle', 'moi', 'sur', '√†', 'dans', 'pour', 'par'
    }
    
    # Extraire les mots
    words = re.findall(r'\b\w+\b', question.lower())
    
    # Filtrer et garder les mots significatifs (> 3 caract√®res)
    keywords = [w for w in words if w not in stop_words and len(w) > 3]
    
    return keywords[:5]  # Limiter √† 5 mots-cl√©s

# Initialize session state
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'debug_mode' not in st.session_state:
    st.session_state.debug_mode = False

# Initialize components
components = init_components()

if components is None:
    st.stop()

# Main UI
st.title("üß† Knowledge Graph RAG")
st.markdown("Posez des questions sur votre corpus de documents")

# Sidebar with parameters
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    
    max_depth = st.slider("Profondeur de parcours du graphe", 1, 3, 2)
    top_k = st.slider("Nombre de r√©sultats vectoriels", 5, 20, 10)
    
    st.markdown("---")
    
    # Debug mode
    st.session_state.debug_mode = st.checkbox("Mode Debug", value=st.session_state.debug_mode)
    
    st.markdown("---")
    st.header("üìä Statistiques")
    
    # Display stats
    if st.button("Rafra√Æchir les stats"):
        with st.spinner("Calcul des statistiques..."):
            try:
                # Count entities by type
                entity_types = {}
                for etype in ['PERSON', 'ORG', 'GPE', 'DATE', 'EVENT', 'PRODUCT']:
                    entities = components['graph_queries'].search_entities_by_type(etype, limit=1000)
                    if entities:
                        entity_types[etype] = len(entities)
                
                if entity_types:
                    st.write("**Entit√©s par type:**")
                    for etype, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True):
                        st.write(f"- {etype}: {count}")
                else:
                    st.info("Aucune statistique disponible.")
                    
            except Exception as e:
                st.error(f"Erreur: {e}")
    
    st.markdown("---")
    
    # Requ√™tes exemples
    st.header("üí° Exemples")
    
    if st.button("Qui est Napoleon?"):
        st.session_state.example_query = "Qui est Napoleon Bonaparte?"
    if st.button("Qu'est-ce que Paris?"):
        st.session_state.example_query = "Parle-moi de Paris"
    if st.button("Info sur France"):
        st.session_state.example_query = "Qu'est-ce que la France?"

# Chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "debug_info" in message and st.session_state.debug_mode:
            with st.expander("üîç Debug Info"):
                st.json(message["debug_info"])
        if "sources" in message and message["sources"]:
            with st.expander("üìö Sources"):
                for source in message["sources"]:
                    st.write(f"- {source}")

# Use example query if set
if 'example_query' in st.session_state:
    prompt = st.session_state.example_query
    del st.session_state.example_query
else:
    # Chat input
    prompt = st.chat_input("Posez votre question...")

if prompt:
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Generate response
    with st.chat_message("assistant"):
        debug_info = {}
        
        try:
            with st.spinner("Recherche dans le graphe..."):
                # 1. Extract entities from question
                entities_in_question = components['entity_extractor'].extract_entities(prompt)
                entity_names = [e['text'] for e in entities_in_question]
                
                debug_info['entities_extracted'] = entity_names
                
                # Debug mode - show extracted entities
                if st.session_state.debug_mode:
                    with st.expander("üîç Debug: Entit√©s extraites de la question"):
                        if entity_names:
                            st.write(f"‚úì Trouv√©es: {entity_names}")
                        else:
                            st.write("‚ö†Ô∏è Aucune entit√© extraite par spaCy")
                
                # 2. Vector search (always perform, even without entities)
                vector_results = components['vector_store'].search(prompt, top_k=top_k)
                
                debug_info['vector_results_count'] = len(vector_results)
                
                if st.session_state.debug_mode:
                    with st.expander("üîç Debug: R√©sultats de la recherche vectorielle"):
                        if vector_results:
                            st.write(f"‚úì Trouv√©s: {len(vector_results)} r√©sultats")
                            for i, res in enumerate(vector_results[:3], 1):
                                st.write(f"{i}. {res.get('document', 'N/A')}")
                        else:
                            st.write("‚ö†Ô∏è Aucun r√©sultat vectoriel")
                
                # 3. Fallback strategies if no entities detected
                if not entity_names:
                    # Strategy 1: Extract from vector results
                    if vector_results:
                        if st.session_state.debug_mode:
                            st.info("üí° Strat√©gie 1: Extraction d'entit√©s des r√©sultats vectoriels...")
                        
                        for result in vector_results[:5]:
                            metadata = result.get('metadata', {})
                            if metadata.get('text'):
                                entity_names.append(metadata['text'])
                    
                    # Strategy 2: Extract keywords from question
                    if not entity_names:
                        if st.session_state.debug_mode:
                            st.info("üí° Strat√©gie 2: Utilisation de mots-cl√©s...")
                        
                        keywords = extract_keywords_from_question(prompt)
                        entity_names = keywords
                        debug_info['fallback_keywords'] = keywords
                
                debug_info['final_entity_names'] = entity_names
                
                # 4. Graph traversal
                traverser = GraphTraverser(components['graph_queries'])
                graph_context = traverser.traverse_from_entities(entity_names, max_depth=max_depth)
                
                debug_info['graph_entities_found'] = len(graph_context.get('entities', []))
                debug_info['graph_relations_found'] = len(graph_context.get('relationships', []))
                
                if st.session_state.debug_mode:
                    with st.expander("üîç Debug: Contexte du graphe"):
                        st.write(f"Entit√©s trouv√©es: {len(graph_context.get('entities', []))}")
                        st.write(f"Relations trouv√©es: {len(graph_context.get('relationships', []))}")
                        if graph_context.get('entities'):
                            st.write("Premi√®res entit√©s:")
                            for ent in graph_context['entities'][:5]:
                                st.write(f"- {ent.get('name', 'N/A')} ({ent.get('type', 'unknown')})")
                
                # 5. Build context (combine vector and graph results)
                builder = ContextBuilder()
                context = builder.build_context(vector_results, graph_context)
                
                debug_info['context_length'] = len(context)
                
                # 6. Check if we have enough context
                if not graph_context.get('entities') and not vector_results:
                    st.warning("‚ö†Ô∏è Aucune information trouv√©e.")
                    st.info(f"**Recherch√©:** {', '.join(entity_names)}")
                    st.info("**Suggestions:**")
                    st.info("- V√©rifiez que le corpus contient des informations sur ce sujet")
                    st.info("- Essayez une question plus g√©n√©rale")
                    st.info("- Utilisez les exemples dans la barre lat√©rale")
                    
                    answer = "Je n'ai pas trouv√© d'information sur ce sujet dans le corpus."
                    sources = []
                else:
                    # 7. Generate answer
                    result = components['llm'].answer_question(prompt, context)
                    answer = result['answer']
                    
                    # Display answer
                    st.markdown(answer)
                    
                    # Display sources
                    sources = builder.format_sources(graph_context)
                    if sources:
                        with st.expander("üìö Sources"):
                            for source in sources:
                                st.write(f"- {source}")
                    
                    # Display context (debug)
                    if st.session_state.debug_mode:
                        with st.expander("üìÑ Contexte utilis√©"):
                            st.text(context[:1000] + "..." if len(context) > 1000 else context)
        
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la g√©n√©ration de la r√©ponse: {e}")
            st.info("V√©rifiez que:")
            st.info("- Neo4j est d√©marr√©")
            st.info("- Le graphe est construit (python scripts/03_build_graph.py)")
            st.info("- Les embeddings sont g√©n√©r√©s (python scripts/04_generate_embeddings.py)")
            st.info("- ANTHROPIC_API_KEY ou DEEPSEEK_API_KEY est d√©fini dans .env")
            
            if st.session_state.debug_mode:
                import traceback
                st.code(traceback.format_exc())
            
            answer = "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse."
            sources = []
    
    # Save response
    message_data = {
        "role": "assistant",
        "content": answer if 'answer' in locals() else "Erreur",
        "sources": sources if 'sources' in locals() else []
    }
    
    if st.session_state.debug_mode:
        message_data["debug_info"] = debug_info
    
    st.session_state.messages.append(message_data)

# Footer
st.markdown("---")
st.markdown("*Propuls√© par Claude/DeepSeek, Neo4j et Sentence Transformers*")