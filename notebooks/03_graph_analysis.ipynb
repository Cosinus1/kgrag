{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse du graphe de connaissances\n",
    "\n",
    "Ce notebook analyse le graphe de connaissances construit à partir des documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.graph.graph_queries import GraphQueries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connexion au graphe Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Initialiser les requêtes\n",
    "graph_queries = GraphQueries(\n",
    "    uri=os.getenv(\"NEO4J_URI\"),\n",
    "    user=os.getenv(\"NEO4J_USER\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\")\n",
    ")\n",
    "\n",
    "print(\"Connexion établie au graphe Neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Statistiques du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités par type\n",
    "entity_types = ['PERSON', 'ORG', 'GPE', 'DATE', 'EVENT', 'PRODUCT']\n",
    "type_counts = {}\n",
    "\n",
    "for etype in entity_types:\n",
    "    entities = graph_queries.search_entities_by_type(etype, limit=1000)\n",
    "    type_counts[etype] = len(entities)\n",
    "\n",
    "print(\"Nombre d'entités par type:\")\n",
    "for etype, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {etype}: {count}\")\n",
    "\n",
    "total_entities = sum(type_counts.values())\n",
    "print(f\"\\nTotal d'entités: {total_entities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse des relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser quelques entités importantes\n",
    "important_entities = []\n",
    "\n",
    "# Chercher des entités avec beaucoup de relations\n",
    "for etype in ['PERSON', 'ORG', 'GPE']:\n",
    "    entities = graph_queries.search_entities_by_type(etype, limit=20)\n",
    "    for entity in entities:\n",
    "        entity_name = entity['name']\n",
    "        neighbors = graph_queries.get_neighbors(entity_name, max_depth=1)\n",
    "        if len(neighbors) > 5:  # Entités avec au moins 5 connexions\n",
    "            important_entities.append({\n",
    "                'name': entity_name,\n",
    "                'type': etype,\n",
    "                'connections': len(neighbors),\n",
    "                'neighbors': neighbors\n",
    "            })\n",
    "\n",
    "# Trier par nombre de connexions\n",
    "important_entities.sort(key=lambda x: x['connections'], reverse=True)\n",
    "\n",
    "print(\"Entités les plus connectées:\")\n",
    "for i, entity in enumerate(important_entities[:10], 1):\n",
    "    print(f\"  {i}. {entity['name']} ({entity['type']}): {entity['connections']} connexions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisation du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un sous-graphe pour visualisation\n",
    "import networkx as nx\n",
    "\n",
    "# Prendre les 5 entités les plus connectées\n",
    "top_entities = important_entities[:5]\n",
    "G = nx.Graph()\n",
    "\n",
    "# Ajouter les nœuds\n",
    "for entity in top_entities:\n",
    "    G.add_node(entity['name'], type=entity['type'], size=entity['connections'])\n",
    "    \n",
    "    # Ajouter quelques voisins\n",
    "    for neighbor in entity['neighbors'][:3]:  # Prendre les 3 premiers voisins\n",
    "        neighbor_name = neighbor['entity']['name']\n",
    "        neighbor_type = neighbor['entity'].get('type', 'unknown')\n",
    "        G.add_node(neighbor_name, type=neighbor_type)\n",
    "        G.add_edge(entity['name'], neighbor_name)\n",
    "\n",
    "# Visualiser\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Positions\n",
    "pos = nx.spring_layout(G, k=2, iterations=50)\n",
    "\n",
    "# Couleurs par type\n",
    "color_map = {\n",
    "    'PERSON': '#FF6B6B',\n",
    "    'ORG': '#4ECDC4',\n",
    "    'GPE': '#45B7D1',\n",
    "    'DATE': '#FFA07A',\n",
    "    'EVENT': '#98D8C8',\n",
    "    'PRODUCT': '#F7DC6F',\n",
    "    'unknown': '#95A5A6'\n",
    "}\n",
    "\n",
    "node_colors = [color_map.get(G.nodes[node].get('type', 'unknown'), '#95A5A6') for node in G.nodes()]\n",
    "node_sizes = [G.nodes[node].get('size', 300) * 10 if 'size' in G.nodes[node] else 300 for node in G.nodes()]\n",
    "\n",
    "# Dessiner\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.5, width=1)\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold')\n",
    "\n",
    "plt.title(\"Sous-graphe des entités les plus connectées\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse des chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver des chemins entre entités importantes\n",
    "if len(top_entities) >= 2:\n",
    "    entity1 = top_entities[0]['name']\n",
    "    entity2 = top_entities[1]['name']\n",
    "    \n",
    "    print(f\"Recherche du chemin entre {entity1} et {entity2}...\")\n",
    "    path = graph_queries.find_path(entity1, entity2)\n",
    "    \n",
    "    if path:\n",
    "        print(\"\\nChemin trouvé:\")\n",
    "        nodes = path['nodes']\n",
    "        relationships = path['relationships']\n",
    "        \n",
    "        for i, node in enumerate(nodes):\n",
    "            print(f\"  {i+1}. {node['name']} ({node.get('type', 'unknown')})\")\n",
    "            if i < len(relationships):\n",
    "                rel = relationships[i]\n",
    "                print(f\"     → [{rel.get('type', 'relates_to')}] →\")\n",
    "    else:\n",
    "        print(\"Aucun chemin direct trouvé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Métriques du graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer quelques métriques de base\n",
    "print(\"Métriques du graphe:\")\n",
    "\n",
    "# Degré moyen\n",
    "degrees = []\n",
    "for entity in important_entities[:20]:  # Échantillon\n",
    "    degrees.append(entity['connections'])\n",
    "\n",
    "if degrees:\n",
    "    avg_degree = sum(degrees) / len(degrees)\n",
    "    max_degree = max(degrees)\n",
    "    min_degree = min(degrees)\n",
    "    \n",
    "    print(f\"  Degré moyen: {avg_degree:.2f}\")\n",
    "    print(f\"  Degré maximum: {max_degree}\")\n",
    "    print(f\"  Degré minimum: {min_degree}\")\n",
    "    \n",
    "    # Distribution des degrés\n",
    "    degree_counts = Counter(degrees)\n",
    "    print(\"\\nDistribution des degrés:\")\n",
    "    for degree, count in sorted(degree_counts.items()):\n",
    "        print(f\"  Degré {degree}: {count} entités\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sauvegarde des analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données d'analyse\n",
    "analysis_data = {\n",
    "    'entity_type_distribution': type_counts,\n",
    "    'important_entities': important_entities[:20],\n",
    "    'graph_metrics': {\n",
    "        'total_entities': total_entities,\n",
    "        'avg_degree': avg_degree if 'avg_degree' in locals() else 0,\n",
    "        'max_degree': max_degree if 'max_degree' in locals() else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarder\n",
    "Path(\"../data/analysis\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"../data/analysis/graph_analysis.json\", 'w') as f:\n",
    "    json.dump(analysis_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nAnalyse sauvegardée dans ../data/analysis/graph_analysis.json\")\n",
    "\n",
    "# Fermer la connexion\n",
    "graph_queries.close()\n",
    "print(\"Connexion fermée.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
