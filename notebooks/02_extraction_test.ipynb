{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test d'extraction d'entités et relations\n",
    "\n",
    "Ce notebook teste l'extraction d'entités et de relations depuis les documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.extraction.entity_extractor import EntityExtractor\n",
    "from src.extraction.relation_extractor import RelationExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Charger les documents traités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les documents\n",
    "with open(\"../data/processed/documents.json\", 'r') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "print(f\"Nombre de documents chargés: {len(documents)}\")\n",
    "\n",
    "# Prendre un échantillon pour les tests\n",
    "sample_docs = documents[:5]  # Premier 5 documents\n",
    "print(f\"Échantillon de {len(sample_docs)} documents pour les tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test d'extraction d'entités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser l'extracteur\n",
    "entity_extractor = EntityExtractor()\n",
    "\n",
    "# Extraire les entités d'un document\n",
    "test_doc = sample_docs[0]\n",
    "print(f\"Document test: {test_doc['filename']}\")\n",
    "print(f\"Longueur du texte: {len(test_doc['text'])} caractères\\n\")\n",
    "\n",
    "entities = entity_extractor.extract_entities(test_doc['text'])\n",
    "print(f\"Nombre d'entités extraites: {len(entities)}\")\n",
    "\n",
    "# Afficher les entités par type\n",
    "entity_types = {}\n",
    "for entity in entities:\n",
    "    entity_types[entity['label']] = entity_types.get(entity['label'], 0) + 1\n",
    "\n",
    "print(\"\\nRépartition des entités par type:\")\n",
    "for etype, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {etype}: {count}\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "print(\"\\nExemples d'entités:\")\n",
    "for i, entity in enumerate(entities[:10], 1):\n",
    "    print(f\"  {i}. {entity['text']} ({entity['label']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test d'extraction de relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser l'extracteur de relations (sans LLM pour les tests)\n",
    "relation_extractor = RelationExtractor(use_llm=False)\n",
    "\n",
    "# Extraire les relations\n",
    "relations = relation_extractor.extract_relations(test_doc['text'])\n",
    "print(f\"Nombre de relations extraites: {len(relations)}\")\n",
    "\n",
    "# Afficher quelques relations\n",
    "print(\"\\nExemples de relations:\")\n",
    "for i, rel in enumerate(relations[:10], 1):\n",
    "    print(f\"  {i}. {rel.get('subject', '?')} --[{rel.get('predicate', '?')}]--> {rel.get('object', '?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyse sur l'ensemble des documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les entités de tous les documents\n",
    "print(\"Extraction des entités sur tous les documents...\")\n",
    "all_entities = entity_extractor.extract_from_documents(documents)\n",
    "\n",
    "# Statistiques globales\n",
    "total_entities = 0\n",
    "entity_type_dist = {}\n",
    "\n",
    "for doc_entities in all_entities:\n",
    "    for entity in doc_entities['entities']:\n",
    "        total_entities += 1\n",
    "        entity_type_dist[entity['label']] = entity_type_dist.get(entity['label'], 0) + 1\n",
    "\n",
    "print(f\"\\nStatistiques globales:\")\n",
    "print(f\"Nombre total d'entités: {total_entities}\")\n",
    "print(f\"Nombre moyen d'entités par document: {total_entities/len(documents):.1f}\")\n",
    "\n",
    "print(\"\\nDistribution des types d'entités:\")\n",
    "for etype, count in sorted(entity_type_dist.items(), key=lambda x: x[1], reverse=True):\n",
    "    percentage = (count / total_entities) * 100\n",
    "    print(f\"  {etype}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Distribution des types d'entités\n",
    "etype_df = pd.DataFrame(list(entity_type_dist.items()), columns=['Type', 'Count'])\n",
    "etype_df = etype_df.sort_values('Count', ascending=False)\n",
    "etype_df.plot(kind='bar', x='Type', y='Count', ax=axes[0], title='Distribution des types d\\'entités')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Entités les plus fréquentes\n",
    "entity_counts = {}\n",
    "for doc_entities in all_entities:\n",
    "    for entity in doc_entities['entities']:\n",
    "        key = (entity['text'].lower(), entity['label'])\n",
    "        entity_counts[key] = entity_counts.get(key, 0) + 1\n",
    "\n",
    "# Top 10 des entités les plus fréquentes\n",
    "top_entities = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "top_df = pd.DataFrame([(f\"{text} ({label})\", count) for (text, label), count in top_entities], \n",
    "                      columns=['Entity', 'Count'])\n",
    "top_df.plot(kind='barh', x='Entity', y='Count', ax=axes[1], title='Top 10 des entités les plus fréquentes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sauvegarde des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder les entités extraites\n",
    "Path(\"../data/entities\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"../data/entities/entities.json\", 'w') as f:\n",
    "    json.dump(all_entities, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Entités sauvegardées dans ../data/entities/entities.json\")\n",
    "print(f\"Total: {len(all_entities)} documents avec entités\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
